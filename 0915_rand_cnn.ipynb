{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0915_rand_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlMzPr6ofxNMqDEeO1mH8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seawavve/pilab/blob/master/0915_rand_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcsT-XVPAiTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "734496aa-d973-4166-8d85-5058366c556d"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "'''\n",
        "pilab seawavve\n",
        "random cnn\n",
        "2020.05.20~\n",
        "16layers 4shortcuts\n",
        "Acc: 93.44%  Epoch:43\n",
        "\n",
        "****PATCH NOTE****\n",
        "0520 cnn network구성\n",
        "0000 EarlyStopping&ModelCheckpoint\n",
        "0000 이미지증강\n",
        "0621 bypass\n",
        "0902 random\n",
        "0908 depth&add확률 조정\n",
        "0914 shortcut조정\n",
        "'''\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets\n",
        "\n",
        "\n",
        "def make_rand(net_list):         #파생된 레이어들을 list에 담아 반환\n",
        "  lis=list()\n",
        "  re_seed=random.randint(1,4)  #파생레이어 1~4개 생성\n",
        "  for i in range(re_seed):\n",
        "    seed=random.randint(1,4)    #한 레이어에서 파생레이어 생성\n",
        "    if seed==1:\n",
        "     im_output= layers.Conv2D(filters=64, kernel_size=[3,3], padding='same', activation='relu')(output)\n",
        "    elif seed==2:\n",
        "      im_output= layers.Dropout(rate=0.25)(output)\n",
        "    elif seed==3:\n",
        "     im_output= layers.MaxPooling2D(pool_size=[3, 3], padding='same', strides=1)(output)\n",
        "    elif seed==4:\n",
        "     im_output = layers.Activation('relu')(output)\n",
        "    lis.append(im_output)\n",
        "  return lis\n",
        "\n",
        "def make_short_cut(a_layer,b_layer):  # 받은 두개의 레이어로 shortcut을 만들어 반환\n",
        "  im_output = layers.Add()([a_layer,b_layer])\n",
        "  return im_output\n",
        "\n",
        "print('Python version : ', sys.version)\n",
        "print('Keras version : ', keras.__version__)\n",
        "\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 300\n",
        "filename = 'checkpoint.h5'.format(epochs, batch_size)\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss',mode='min',patience=15,verbose=1)                           #얼리스타핑\n",
        "checkpoint=ModelCheckpoint(filename,monitor='val_loss',verbose=1,save_best_only=True,mode='auto')           #체크포인트\n",
        "\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "inputs = keras.Input(shape=input_shape, name='input' )\n",
        "output= layers.Conv2D(filters=64, kernel_size=[3,3], padding='same', activation='relu')(inputs)\n",
        "\n",
        "net_list=list()\n",
        "add_num=0\n",
        "\n",
        "for depth in range(5):                           #깊이정하기\n",
        "  a=make_rand(net_list)                         #랜덤레이어 생성\n",
        "  net_list.extend(a)\n",
        "  print('make_list로 만든 리스트의 길이:',len(a))\n",
        "  if len(a)==1:r_num=0                         #a 중에서 하나 레이어 골라서 output에 붙이기\n",
        "  else:r_num=random.randint(0,len(a)-1)   \n",
        "  print('랜덤 index number:',r_num+1)                   \n",
        "  output=a[r_num]   \n",
        "  #random\n",
        "  short_cut_dec=random.randint(1,5)             #40%확률적으로 shortcut\n",
        "  if (short_cut_dec==1 or short_cut_dec==2) and len(net_list)>1:\n",
        "    add_num=add_num+1\n",
        "    add_layer_num=random.randint(0,len(net_list)-1)\n",
        "    add_list=[] #인덱스 저장해서 같은거 있는지 확인하려고 만든 리스트\n",
        "    for _ in range( random.randint(0,len(net_list)-1) ): #random개만큼 add한다\n",
        "      a_layer_num=random.randint(0,len(net_list)-1)\n",
        "      #if 같은거 있으면 바꾸기\n",
        "      add_list.append(a_layer_num)\n",
        "      c=make_short_cut(net_list[a_layer_num],output)\n",
        "      output=c\n",
        "    net_list.append(net_list)\n",
        "\n",
        "output = layers.GlobalAveragePooling2D()(output)\n",
        "output = layers.Dense(1000, activation='relu')(output)\n",
        "dropout = layers.Dropout(rate=0.25)(output)\n",
        "output = layers.Dense(10, activation='softmax')(dropout)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test),callbacks=[checkpoint,early_stopping])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:',  score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save('MNIST_CNN_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version :  3.6.9 (default, Jul 17 2020, 12:50:27) \n",
            "[GCC 8.4.0]\n",
            "Keras version :  2.4.0\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "make_list로 만든 리스트의 길이: 1\n",
            "랜덤 index number: 1\n",
            "make_list로 만든 리스트의 길이: 2\n",
            "랜덤 index number: 2\n",
            "make_list로 만든 리스트의 길이: 3\n",
            "랜덤 index number: 2\n",
            "make_list로 만든 리스트의 길이: 2\n",
            "랜덤 index number: 2\n",
            "make_list로 만든 리스트의 길이: 4\n",
            "랜덤 index number: 4\n",
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 64)   640         input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 64)   36928       conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 64)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 64)   36928       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 28, 28, 64)   0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 28, 28, 64)   36928       conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 28, 28, 64)   0           activation_7[0][0]               \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 64)   36928       conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 28, 28, 64)   0           conv2d_12[0][0]                  \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 28, 28, 64)   0           conv2d_10[0][0]                  \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 28, 28, 64)   0           conv2d_6[0][0]                   \n",
            "                                                                 add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 28, 28, 64)   0           conv2d_9[0][0]                   \n",
            "                                                                 add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 28, 28, 64)   0           dropout_12[0][0]                 \n",
            "                                                                 add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 64)           0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1000)         65000       global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 1000)         0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           10010       dropout_13[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 223,362\n",
            "Trainable params: 223,362\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 1.0297 - accuracy: 0.6047\n",
            "Epoch 00001: val_loss improved from inf to 0.70073, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.0297 - accuracy: 0.6047 - val_loss: 0.7007 - val_accuracy: 0.7456\n",
            "Epoch 2/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.7605\n",
            "Epoch 00002: val_loss improved from 0.70073 to 0.60492, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.6506 - accuracy: 0.7605 - val_loss: 0.6049 - val_accuracy: 0.7846\n",
            "Epoch 3/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.5220 - accuracy: 0.8086\n",
            "Epoch 00003: val_loss improved from 0.60492 to 0.46303, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.5220 - accuracy: 0.8086 - val_loss: 0.4630 - val_accuracy: 0.8362\n",
            "Epoch 4/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.8398\n",
            "Epoch 00004: val_loss improved from 0.46303 to 0.42212, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.4413 - accuracy: 0.8398 - val_loss: 0.4221 - val_accuracy: 0.8486\n",
            "Epoch 5/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8592\n",
            "Epoch 00005: val_loss improved from 0.42212 to 0.36737, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3895 - accuracy: 0.8592 - val_loss: 0.3674 - val_accuracy: 0.8719\n",
            "Epoch 6/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.8697\n",
            "Epoch 00006: val_loss did not improve from 0.36737\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3610 - accuracy: 0.8697 - val_loss: 0.3708 - val_accuracy: 0.8694\n",
            "Epoch 7/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8781\n",
            "Epoch 00007: val_loss improved from 0.36737 to 0.32200, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3369 - accuracy: 0.8781 - val_loss: 0.3220 - val_accuracy: 0.8858\n",
            "Epoch 8/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.8859\n",
            "Epoch 00008: val_loss did not improve from 0.32200\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3143 - accuracy: 0.8859 - val_loss: 0.3280 - val_accuracy: 0.8829\n",
            "Epoch 9/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.8910\n",
            "Epoch 00009: val_loss did not improve from 0.32200\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.2991 - accuracy: 0.8910 - val_loss: 0.3298 - val_accuracy: 0.8832\n",
            "Epoch 10/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2917 - accuracy: 0.8942\n",
            "Epoch 00010: val_loss improved from 0.32200 to 0.29753, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2917 - accuracy: 0.8942 - val_loss: 0.2975 - val_accuracy: 0.8941\n",
            "Epoch 11/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.8967\n",
            "Epoch 00011: val_loss improved from 0.29753 to 0.28430, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2822 - accuracy: 0.8967 - val_loss: 0.2843 - val_accuracy: 0.8984\n",
            "Epoch 12/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.9024\n",
            "Epoch 00012: val_loss did not improve from 0.28430\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.2671 - accuracy: 0.9024 - val_loss: 0.2845 - val_accuracy: 0.8957\n",
            "Epoch 13/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.9037\n",
            "Epoch 00013: val_loss improved from 0.28430 to 0.26423, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2617 - accuracy: 0.9037 - val_loss: 0.2642 - val_accuracy: 0.9031\n",
            "Epoch 14/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.9065\n",
            "Epoch 00014: val_loss did not improve from 0.26423\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2547 - accuracy: 0.9065 - val_loss: 0.2920 - val_accuracy: 0.8914\n",
            "Epoch 15/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9102\n",
            "Epoch 00015: val_loss improved from 0.26423 to 0.25253, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2449 - accuracy: 0.9102 - val_loss: 0.2525 - val_accuracy: 0.9089\n",
            "Epoch 16/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.9120\n",
            "Epoch 00016: val_loss did not improve from 0.25253\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2403 - accuracy: 0.9120 - val_loss: 0.2795 - val_accuracy: 0.9003\n",
            "Epoch 17/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9135\n",
            "Epoch 00017: val_loss did not improve from 0.25253\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2349 - accuracy: 0.9135 - val_loss: 0.2548 - val_accuracy: 0.9106\n",
            "Epoch 18/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9159\n",
            "Epoch 00018: val_loss did not improve from 0.25253\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2297 - accuracy: 0.9159 - val_loss: 0.2582 - val_accuracy: 0.9085\n",
            "Epoch 19/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9165\n",
            "Epoch 00019: val_loss improved from 0.25253 to 0.25221, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2262 - accuracy: 0.9165 - val_loss: 0.2522 - val_accuracy: 0.9105\n",
            "Epoch 20/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9193\n",
            "Epoch 00020: val_loss did not improve from 0.25221\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2201 - accuracy: 0.9193 - val_loss: 0.2635 - val_accuracy: 0.9041\n",
            "Epoch 21/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9198\n",
            "Epoch 00021: val_loss improved from 0.25221 to 0.24652, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2184 - accuracy: 0.9198 - val_loss: 0.2465 - val_accuracy: 0.9113\n",
            "Epoch 22/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.9226\n",
            "Epoch 00022: val_loss improved from 0.24652 to 0.24556, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2100 - accuracy: 0.9226 - val_loss: 0.2456 - val_accuracy: 0.9125\n",
            "Epoch 23/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2074 - accuracy: 0.9232\n",
            "Epoch 00023: val_loss did not improve from 0.24556\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2074 - accuracy: 0.9232 - val_loss: 0.2544 - val_accuracy: 0.9114\n",
            "Epoch 24/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9263\n",
            "Epoch 00024: val_loss improved from 0.24556 to 0.23607, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2019 - accuracy: 0.9263 - val_loss: 0.2361 - val_accuracy: 0.9174\n",
            "Epoch 25/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.2002 - accuracy: 0.9263\n",
            "Epoch 00025: val_loss did not improve from 0.23607\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.2001 - accuracy: 0.9263 - val_loss: 0.2386 - val_accuracy: 0.9156\n",
            "Epoch 26/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9280\n",
            "Epoch 00026: val_loss improved from 0.23607 to 0.23436, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1951 - accuracy: 0.9280 - val_loss: 0.2344 - val_accuracy: 0.9167\n",
            "Epoch 27/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.9286\n",
            "Epoch 00027: val_loss did not improve from 0.23436\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.1940 - accuracy: 0.9286 - val_loss: 0.2354 - val_accuracy: 0.9157\n",
            "Epoch 28/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9308\n",
            "Epoch 00028: val_loss improved from 0.23436 to 0.23144, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1885 - accuracy: 0.9308 - val_loss: 0.2314 - val_accuracy: 0.9191\n",
            "Epoch 29/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.9327\n",
            "Epoch 00029: val_loss did not improve from 0.23144\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.1843 - accuracy: 0.9327 - val_loss: 0.2326 - val_accuracy: 0.9184\n",
            "Epoch 30/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9344\n",
            "Epoch 00030: val_loss did not improve from 0.23144\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.1803 - accuracy: 0.9344 - val_loss: 0.2384 - val_accuracy: 0.9147\n",
            "Epoch 31/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1818 - accuracy: 0.9331\n",
            "Epoch 00031: val_loss did not improve from 0.23144\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1818 - accuracy: 0.9331 - val_loss: 0.2396 - val_accuracy: 0.9165\n",
            "Epoch 32/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9359\n",
            "Epoch 00032: val_loss improved from 0.23144 to 0.22422, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1741 - accuracy: 0.9359 - val_loss: 0.2242 - val_accuracy: 0.9226\n",
            "Epoch 33/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9368\n",
            "Epoch 00033: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1702 - accuracy: 0.9368 - val_loss: 0.2261 - val_accuracy: 0.9222\n",
            "Epoch 34/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1669 - accuracy: 0.9382\n",
            "Epoch 00034: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1669 - accuracy: 0.9382 - val_loss: 0.2340 - val_accuracy: 0.9198\n",
            "Epoch 35/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1617 - accuracy: 0.9395\n",
            "Epoch 00035: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1617 - accuracy: 0.9395 - val_loss: 0.2461 - val_accuracy: 0.9202\n",
            "Epoch 36/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1617 - accuracy: 0.9406\n",
            "Epoch 00036: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1617 - accuracy: 0.9406 - val_loss: 0.2310 - val_accuracy: 0.9229\n",
            "Epoch 37/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9419\n",
            "Epoch 00037: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1587 - accuracy: 0.9419 - val_loss: 0.2472 - val_accuracy: 0.9185\n",
            "Epoch 38/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9420\n",
            "Epoch 00038: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1557 - accuracy: 0.9420 - val_loss: 0.2343 - val_accuracy: 0.9202\n",
            "Epoch 39/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9446\n",
            "Epoch 00039: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1537 - accuracy: 0.9446 - val_loss: 0.2302 - val_accuracy: 0.9191\n",
            "Epoch 40/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.9444\n",
            "Epoch 00040: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1502 - accuracy: 0.9444 - val_loss: 0.2323 - val_accuracy: 0.9255\n",
            "Epoch 41/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1481 - accuracy: 0.9445\n",
            "Epoch 00041: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1481 - accuracy: 0.9445 - val_loss: 0.2451 - val_accuracy: 0.9213\n",
            "Epoch 42/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9473\n",
            "Epoch 00042: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1429 - accuracy: 0.9473 - val_loss: 0.2422 - val_accuracy: 0.9213\n",
            "Epoch 43/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9463\n",
            "Epoch 00043: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1429 - accuracy: 0.9463 - val_loss: 0.2301 - val_accuracy: 0.9248\n",
            "Epoch 44/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9483\n",
            "Epoch 00044: val_loss did not improve from 0.22422\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1406 - accuracy: 0.9483 - val_loss: 0.2303 - val_accuracy: 0.9256\n",
            "Epoch 45/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9487\n",
            "Epoch 00045: val_loss improved from 0.22422 to 0.21939, saving model to checkpoint.h5\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1391 - accuracy: 0.9487 - val_loss: 0.2194 - val_accuracy: 0.9283\n",
            "Epoch 46/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9499\n",
            "Epoch 00046: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1349 - accuracy: 0.9499 - val_loss: 0.2402 - val_accuracy: 0.9198\n",
            "Epoch 47/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9501\n",
            "Epoch 00047: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1333 - accuracy: 0.9501 - val_loss: 0.2419 - val_accuracy: 0.9230\n",
            "Epoch 48/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9520\n",
            "Epoch 00048: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1284 - accuracy: 0.9520 - val_loss: 0.2326 - val_accuracy: 0.9253\n",
            "Epoch 49/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9528\n",
            "Epoch 00049: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1275 - accuracy: 0.9528 - val_loss: 0.2292 - val_accuracy: 0.9276\n",
            "Epoch 50/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.9538\n",
            "Epoch 00050: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1232 - accuracy: 0.9538 - val_loss: 0.2385 - val_accuracy: 0.9262\n",
            "Epoch 51/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9533\n",
            "Epoch 00051: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1247 - accuracy: 0.9533 - val_loss: 0.2461 - val_accuracy: 0.9210\n",
            "Epoch 52/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9539\n",
            "Epoch 00052: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1223 - accuracy: 0.9539 - val_loss: 0.2541 - val_accuracy: 0.9194\n",
            "Epoch 53/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9553\n",
            "Epoch 00053: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1189 - accuracy: 0.9553 - val_loss: 0.2368 - val_accuracy: 0.9285\n",
            "Epoch 54/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9553\n",
            "Epoch 00054: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1186 - accuracy: 0.9553 - val_loss: 0.2437 - val_accuracy: 0.9277\n",
            "Epoch 55/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9580\n",
            "Epoch 00055: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1146 - accuracy: 0.9580 - val_loss: 0.2532 - val_accuracy: 0.9265\n",
            "Epoch 56/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9579\n",
            "Epoch 00056: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1119 - accuracy: 0.9579 - val_loss: 0.2604 - val_accuracy: 0.9217\n",
            "Epoch 57/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9584\n",
            "Epoch 00057: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1112 - accuracy: 0.9584 - val_loss: 0.2403 - val_accuracy: 0.9270\n",
            "Epoch 58/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9582\n",
            "Epoch 00058: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1083 - accuracy: 0.9582 - val_loss: 0.2484 - val_accuracy: 0.9278\n",
            "Epoch 59/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9598\n",
            "Epoch 00059: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1072 - accuracy: 0.9598 - val_loss: 0.2508 - val_accuracy: 0.9263\n",
            "Epoch 60/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9609\n",
            "Epoch 00060: val_loss did not improve from 0.21939\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1055 - accuracy: 0.9609 - val_loss: 0.2561 - val_accuracy: 0.9234\n",
            "Epoch 00060: early stopping\n",
            "Test loss: 0.25613537430763245\n",
            "Test accuracy: 0.9233999848365784\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}